{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1UprMbLuyAk",
        "outputId": "cf0f34d4-1e9b-434f-ec02-aca9ac9e95ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:  999\n"
          ]
        }
      ],
      "source": [
        "#%matplotlib inline\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.utils import save_image\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "# Set random seed for reproducibility\n",
        "manualSeed = 999\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "import netCDF4 as nc\n",
        "import scipy.io as sio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F-CYyCKuW7lN"
      },
      "outputs": [],
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVJWNqKZy8GJ",
        "outputId": "2371df47-e884-4d00-cfd3-69852e43cd21"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AMbxL3bvW0lU"
      },
      "outputs": [],
      "source": [
        "def save_some_examples(gen, val_loader, epoch, folder):\n",
        "    x, y = next(iter(val_loader))\n",
        "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "    gen.eval()\n",
        "    with torch.no_grad():\n",
        "        y_fake = gen(x)\n",
        "        y_fake = y_fake * 0.5 + 0.5  # remove normalization#\n",
        "        save_image(y_fake, folder + f\"/y_gen_{epoch}.png\")\n",
        "        save_image(x * 0.5 + 0.5, folder + f\"/input_{epoch}.png\")\n",
        "        if epoch == 1:\n",
        "            save_image(y * 0.5 + 0.5, folder + f\"/label_{epoch}.png\")\n",
        "    gen.train()\n",
        "\n",
        "\n",
        "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    # If we don't do this then it will just have learning rate of old checkpoint\n",
        "    # and it will lead to many hours of debugging \\:\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_jBApRjaFqil"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IzycPhIGOduD"
      },
      "outputs": [],
      "source": [
        "img1 = plt.imread('/content/drive/MyDrive/coarse_grid/timestamp_coarse_10.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.subplots(figsize=(15,10))\n",
        "\n",
        "plt.imshow(img1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "wB-5p25F0JJG",
        "outputId": "d04ed018-3287-4957-d6cb-5c98e39c005b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7030122150>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "i5LfJ4OfO7Wz"
      },
      "outputs": [],
      "source": [
        "transform_only_input = transforms.Compose(\n",
        "    [transforms.ToPILImage(),\n",
        "     transforms.ToTensor(),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ColorJitter(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "     \n",
        "    ]\n",
        ")\n",
        "\n",
        "transform_only_mask = transforms.Compose(\n",
        "    [transforms.ToPILImage(),\n",
        "     transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "        \n",
        "    \n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU1NLtDvO730"
      },
      "source": [
        "# Model initiation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mtaGu-mOHHZl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, down=True, act=\"relu\", use_dropout=False):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(2,2),padding=1,  bias=False)\n",
        "            if down\n",
        "            else nn.ConvTranspose2d(in_channels, out_channels, kernel_size=(2,2),padding=1 , bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU() if act == \"relu\" else nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        self.use_dropout = use_dropout\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.down = down\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return self.dropout(x) if self.use_dropout else x\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels=3, features=64):\n",
        "        super().__init__()\n",
        "        self.initial_down = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode=\"reflect\"),\n",
        "            nn.LeakyReLU(0.2),)\n",
        "        self.down1 = Block(features, features * 2, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down2 = Block(features * 2, features * 4, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down3 = Block(features * 4, features * 8, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down4 = Block(features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down5 = Block(features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down6 = Block(features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.bottleneck = nn.Sequential(nn.Conv2d(features * 8, features * 8, 4, 1, 2), nn.ReLU())\n",
        "\n",
        "\n",
        "        self.up1 = Block(features * 8, features * 8, down=False, act=\"relu\", use_dropout=True)\n",
        "        self.up2 = Block(features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=True)\n",
        "        self.up3 = Block(features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=True)\n",
        "        self.up4 = Block(features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.up5 = Block(features * 8 * 2, features * 4, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.up6 = Block(features * 4 * 2, features * 2, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.up7 = Block(features * 2 * 2, features, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.final_up = nn.Sequential(nn.ConvTranspose2d(features * 2, in_channels, kernel_size=4, stride=2, padding=1),nn.Tanh(),)\n",
        "\n",
        "    def forward(self, x):\n",
        "        d1 = self.initial_down(x)\n",
        "        d2 = self.down1(d1)\n",
        "        d3 = self.down2(d2)\n",
        "        d4 = self.down3(d3)\n",
        "        d5 = self.down4(d4)\n",
        "        d6 = self.down5(d5)\n",
        "        d7 = self.down6(d6)\n",
        "        bottleneck = self.bottleneck(d7)\n",
        "        up1 = self.up1(bottleneck)\n",
        "        up2 = self.up2(torch.cat([up1, d7], 1))\n",
        "        up3 = self.up3(torch.cat([up2, d6], 1))\n",
        "        up4 = self.up4(torch.cat([up3, d5], 1))\n",
        "        up5 = self.up5(torch.cat([up4, d4], 1))\n",
        "        up6 = self.up6(torch.cat([up5, d3], 1))\n",
        "        up7 = self.up7(torch.cat([up6, d2], 1))\n",
        "        return self.final_up(torch.cat([up7, d1], 1))\n",
        "\n",
        "\n",
        "def test_generator():\n",
        "    x = torch.randn((1, 3, 256, 256))\n",
        "    model = Generator(in_channels=3, features=64)\n",
        "    preds = model(x)\n",
        "    print(preds.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UMcqoK-rPFDK"
      },
      "outputs": [],
      "source": [
        "class CNNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride):\n",
        "        super(CNNBlock, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels, out_channels, 2, stride, bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels * 2,\n",
        "                features[0],\n",
        "                kernel_size=4,\n",
        "                stride=2,\n",
        "                padding=1,\n",
        "                padding_mode=\"reflect\",\n",
        "            ),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        layers = []\n",
        "        in_channels = features[0]\n",
        "        for feature in features[1:]:\n",
        "            layers.append(\n",
        "                CNNBlock(in_channels, feature, stride=1 if feature == features[-1] else 2),\n",
        "            )\n",
        "            in_channels = feature\n",
        "\n",
        "        layers.append(\n",
        "            nn.Conv2d(\n",
        "                in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        x = torch.cat([x, y], dim=1)\n",
        "        x = self.initial(x)\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def test_discriminator():\n",
        "    x = torch.randn((1, 3, 256, 256))\n",
        "    y = torch.randn((1, 3, 256, 256))\n",
        "    model = Discriminator(in_channels=3)\n",
        "    preds = model(x, y)\n",
        "    print(model)\n",
        "    print(preds.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SCx-JtoqRaqv"
      },
      "outputs": [],
      "source": [
        "class MapDataset(Dataset):\n",
        "    def __init__(self, root_dir,target_dir):\n",
        "        self.root_dir = root_dir\n",
        "        self.target_dir = target_dir\n",
        "        self.list_files = os.listdir(self.root_dir)\n",
        "        self.list_files_target = os.listdir(self.target_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_file = self.list_files[index]\n",
        "        img_file_target = self.list_files_target[index]\n",
        "        img_path = os.path.join(self.root_dir, img_file)\n",
        "        img_path_target = os.path.join(self.target_dir, img_file_target)\n",
        "       \n",
        "        input_image = np.array(Image.open(img_path))\n",
        "        target_image = np.array(Image.open(img_path_target))\n",
        "        \n",
        "\n",
        " #       augmentations = both_transform(image=input_image, image0=target_image)\n",
        "     \n",
        "\n",
        "     #   input_image = transform_only_input(image=input_image)[\"image\"]\n",
        "      #  target_image = transform_only_mask(image=target_image)[\"image\"]\n",
        "        input_image = transform_only_input(input_image)\n",
        "        target_image = transform_only_mask(target_image)\n",
        "\n",
        "\n",
        "\n",
        "        return input_image, target_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WhtnamJ_UHjm"
      },
      "outputs": [],
      "source": [
        "TRAIN_DIR = \"/content/drive/MyDrive/coarse_grid/\"\n",
        "VAL_DIR = \"/content/drive/MyDrive/fine_grid/\"\n",
        "BATCH_SIZE = 10\n",
        "LEARNING_RATE = 1e-3\n",
        "NUM_WORKERS = 2\n",
        "NUM_EPOCHS = 30\n",
        "CHECKPOINT_DISC = \"disc.pth.tar\"\n",
        "CHECKPOINT_GEN = \"gen.pth.tar\"\n",
        "gen_weights = \"gen_weights.pt.tar\"\n",
        "disc_weights = \"disc_weights.pt.tar\"\n",
        "LOAD_MODEL=False\n",
        "SAVE_MODEL = True\n",
        "loss_disc = []\n",
        "loss_gen = []\n",
        "def train_fn(\n",
        "    disc, gen, loader, opt_disc, opt_gen, l1_loss, bce, g_scaler, d_scaler,\n",
        "learning_rate):\n",
        "    loop = tqdm(loader, leave=True)\n",
        "\n",
        "\n",
        "\n",
        "    for idx, (x, y) in enumerate(loop):\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.to(DEVICE)\n",
        "\n",
        "        # Train Discriminator\n",
        "        with torch.cuda.amp.autocast():\n",
        "            y_fake = gen(x)\n",
        "            D_real = disc(x, y)\n",
        "            D_real_loss = bce(D_real, torch.ones_like(D_real))\n",
        "            D_fake = disc(x, y_fake.detach())\n",
        "            D_fake_loss = bce(D_fake, torch.zeros_like(D_fake))\n",
        "            D_loss = (D_real_loss + D_fake_loss) / 2\n",
        "            loss_disc.append(D_loss.cpu().detach().numpy())\n",
        "\n",
        "        disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "        # Train generator\n",
        "        with torch.cuda.amp.autocast():\n",
        "            D_fake = disc(x, y_fake)\n",
        "            G_fake_loss = bce(D_fake, torch.ones_like(D_fake))\n",
        "            L1 = l1_loss(y_fake, y) * 100\n",
        "            G_loss = G_fake_loss + L1\n",
        "            loss_gen.append(G_loss.cpu().detach().numpy())\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "        if idx % 10 == 0:\n",
        "            loop.set_postfix(\n",
        "                D_real=torch.sigmoid(D_real).mean().item(),\n",
        "                D_fake=torch.sigmoid(D_fake).mean().item(),\n",
        "            )\n",
        "\n",
        "\n",
        "def main():\n",
        "    disc = Discriminator(in_channels=3).to(DEVICE)\n",
        "    gen = Generator(in_channels=3, features=64).to(DEVICE)\n",
        "    opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE , betas=(0.5, 0.999),)\n",
        "    opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE , betas=(0.5, 0.999))\n",
        "    BCE = nn.BCEWithLogitsLoss()\n",
        "    L1_LOSS = nn.L1Loss()\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN, gen, opt_gen, LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_DISC, disc, opt_disc, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "    train_dataset = MapDataset(root_dir=TRAIN_DIR,target_dir=VAL_DIR)\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "    )\n",
        "    g_scaler = torch.cuda.amp.GradScaler()\n",
        "    d_scaler = torch.cuda.amp.GradScaler()\n",
        "    val_dataset = MapDataset(root_dir=VAL_DIR,target_dir=VAL_DIR)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        train_fn(\n",
        "            disc, gen, train_loader, opt_disc, opt_gen, L1_LOSS, BCE, g_scaler, d_scaler,\n",
        "        LEARNING_RATE)\n",
        "\n",
        "        if SAVE_MODEL and epoch % 5 == 0:\n",
        "            torch.save(gen.state_dict(), gen_weights)\n",
        "            torch.save(disc.state_dict(),disc_weights)\n",
        "            save_checkpoint(gen, opt_gen, filename=CHECKPOINT_GEN)\n",
        "            save_checkpoint(disc, opt_disc, filename=CHECKPOINT_DISC)\n",
        "\n",
        "    #    save_some_examples(gen, val_loader, epoch, folder=\"evaluation\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZvpusRv7GS-m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "9d55047a-7a80-4d32-842f-d26c1f13029d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |    5424 MB |    5681 MB |   10564 MB |    5139 MB |\\n|       from large pool |    5418 MB |    5677 MB |   10557 MB |    5138 MB |\\n|       from small pool |       6 MB |       6 MB |       6 MB |       0 MB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |    5424 MB |    5681 MB |   10564 MB |    5139 MB |\\n|       from large pool |    5418 MB |    5677 MB |   10557 MB |    5138 MB |\\n|       from small pool |       6 MB |       6 MB |       6 MB |       0 MB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    6060 MB |    6060 MB |    6060 MB |       0 B  |\\n|       from large pool |    6052 MB |    6052 MB |    6052 MB |       0 B  |\\n|       from small pool |       8 MB |       8 MB |       8 MB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |  302368 KB |  749032 KB |    3840 MB |    3544 MB |\\n|       from large pool |  300484 KB |  747018 KB |    3834 MB |    3541 MB |\\n|       from small pool |    1884 KB |    2034 KB |       5 MB |       3 MB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     249    |     258    |     329    |      80    |\\n|       from large pool |      95    |      96    |     135    |      40    |\\n|       from small pool |     154    |     163    |     194    |      40    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     249    |     258    |     329    |      80    |\\n|       from large pool |      95    |      96    |     135    |      40    |\\n|       from small pool |     154    |     163    |     194    |      40    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      39    |      39    |      39    |       0    |\\n|       from large pool |      35    |      35    |      35    |       0    |\\n|       from small pool |       4    |       4    |       4    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      32    |      32    |      82    |      50    |\\n|       from large pool |      21    |      22    |      49    |      28    |\\n|       from small pool |      11    |      11    |      33    |      22    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QHVRfiNRbTmq"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    dataset = MapDataset(TRAIN_DIR,VAL_DIR)\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=10)\n",
        "  #  for x, y in loader:\n",
        "    #    print(x.shape)\n",
        "    #    save_image(x, \"x.png\")\n",
        "    #    save_image(y, \"y.png\")\n",
        "    #    import sys\n",
        "    #    sys.exit()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXU69ko6yVy5",
        "outputId": "face4766-38d3-4df5-ef2f-6dd6412eba5d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJtO1suJRbFb",
        "outputId": "30d74c40-33ae-465a-a684-19fc44c608b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 149/149 [03:08<00:00,  1.26s/it, D_fake=0.109, D_real=0.885]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 149/149 [02:28<00:00,  1.00it/s, D_fake=0.587, D_real=0.396]\n",
            "100%|██████████| 149/149 [02:28<00:00,  1.00it/s, D_fake=0.297, D_real=0.688]\n",
            "100%|██████████| 149/149 [02:28<00:00,  1.01it/s, D_fake=0.0865, D_real=0.867]\n",
            "100%|██████████| 149/149 [02:28<00:00,  1.01it/s, D_fake=0.12, D_real=0.688]\n",
            "100%|██████████| 149/149 [02:28<00:00,  1.01it/s, D_fake=0.923, D_real=0.533]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 149/149 [02:27<00:00,  1.01it/s, D_fake=0.141, D_real=0.936]\n",
            "100%|██████████| 149/149 [02:27<00:00,  1.01it/s, D_fake=0.132, D_real=0.688]\n",
            "100%|██████████| 149/149 [02:27<00:00,  1.01it/s, D_fake=0.019, D_real=0.975]\n",
            "100%|██████████| 149/149 [02:27<00:00,  1.01it/s, D_fake=0.013, D_real=0.937]\n",
            "100%|██████████| 149/149 [02:27<00:00,  1.01it/s, D_fake=0.0317, D_real=0.988]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 149/149 [02:27<00:00,  1.01it/s, D_fake=0.00674, D_real=0.983]\n",
            "100%|██████████| 149/149 [02:27<00:00,  1.01it/s, D_fake=0.203, D_real=0.805]\n",
            "100%|██████████| 149/149 [02:27<00:00,  1.01it/s, D_fake=0.277, D_real=0.648]\n",
            "100%|██████████| 149/149 [02:28<00:00,  1.01it/s, D_fake=0.0253, D_real=0.994]\n",
            "100%|██████████| 149/149 [02:27<00:00,  1.01it/s, D_fake=0.442, D_real=0.483]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 149/149 [02:27<00:00,  1.01it/s, D_fake=0.0156, D_real=0.966]\n",
            "100%|██████████| 149/149 [02:27<00:00,  1.01it/s, D_fake=0.0228, D_real=0.991]\n",
            "100%|██████████| 149/149 [02:27<00:00,  1.01it/s, D_fake=0.0491, D_real=0.903]\n",
            "100%|██████████| 149/149 [02:27<00:00,  1.01it/s, D_fake=0.0917, D_real=0.928]\n",
            "100%|██████████| 149/149 [02:27<00:00,  1.01it/s, D_fake=0.0901, D_real=0.877]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 149/149 [02:27<00:00,  1.01it/s, D_fake=0.0149, D_real=0.999]\n",
            "100%|██████████| 149/149 [02:27<00:00,  1.01it/s, D_fake=0.0102, D_real=0.967]\n",
            "100%|██████████| 149/149 [02:26<00:00,  1.02it/s, D_fake=0.013, D_real=0.958]\n",
            "100%|██████████| 149/149 [02:26<00:00,  1.01it/s, D_fake=0.833, D_real=0.414]\n",
            "100%|██████████| 149/149 [02:27<00:00,  1.01it/s, D_fake=0.0129, D_real=0.998]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 149/149 [02:26<00:00,  1.02it/s, D_fake=0.12, D_real=0.826]\n",
            "100%|██████████| 149/149 [02:26<00:00,  1.02it/s, D_fake=0.00867, D_real=0.992]\n",
            "100%|██████████| 149/149 [02:26<00:00,  1.02it/s, D_fake=0.0153, D_real=0.995]\n",
            "100%|██████████| 149/149 [02:26<00:00,  1.02it/s, D_fake=0.737, D_real=0.417]\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjoSlUV0dVX6"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator(in_channels=3, features=64).to(DEVICE)\n",
        "opt_gen = optim.Adam(generator.parameters(), lr=LEARNING_RATE , betas=(0.5, 0.999))\n"
      ],
      "metadata": {
        "id": "l-HMj4D7YItg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    # If we don't do this then it will just have learning rate of old checkpoint\n",
        "    # and it will lead to many hours of debugging \\:\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n",
        "    return model\n",
        "\n",
        "gen = load_checkpoint('/content/gen.pth.tar',generator,opt_gen,LEARNING_RATE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNumWovgB8R_",
        "outputId": "4d507284-dcff-48ce-9228-c79722fd615f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Loading checkpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = np.array(Image.open('/content/drive/MyDrive/test/timestamp_coarse_1244.jpg'))\n",
        "target_image = np.array(Image.open('/content/drive/MyDrive/fine_test/timestamp_fine_1244.jpg'))"
      ],
      "metadata": {
        "id": "7z7RFOdOZMCj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = transform_only_input(input_image)"
      ],
      "metadata": {
        "id": "wSIJrJXzYtYj"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_f3H0hvZbJf",
        "outputId": "2632a4f1-be0a-4be8-d4bc-ba557b96eef2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 80, 640])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = gen(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tifmqi-BYeyf",
        "outputId": "c5afc304-0e2a-456b-e0e3-eeef52c7280d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-a3a9147f1dba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-c5c8033127aa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_down\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0md3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    439\u001b[0m             return F.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n\u001b[1;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                             _pair(0), self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [64, 3, 4, 4], but got 3-dimensional input of size [3, 82, 642] instead"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lgLIqusvL58"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "FinalProject.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}